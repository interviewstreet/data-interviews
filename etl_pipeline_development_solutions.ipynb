{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HackerRank Lead Data Engineer Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Pipeline Development\n",
    "\n",
    "During this interview, we aim to evaluate several skills:\n",
    "1. Transform data using SQL\n",
    "2. Manage dataframes with PySpark or similar technologies\n",
    "3. Identify and troubleshoot inconsistencies in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "When you are solving a test on the HackerRank platform, our platform collects click stream data on certain user actions. For example, we receive ping data when you run code, submit code, or view different questions. In this notebook, you will be manipulating a similar set of the click stream data to extract certain features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local\") \\\n",
    "                    .appName(\"etl_pipeline_development\") \\\n",
    "                    .enableHiveSupport() \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### Relevant Tables\n",
    "\n",
    "\\* **Perform any cleaning, exploratory analysis, and/or visualizations for the provided data as needed.**\n",
    "\n",
    "There are several `csv` files we will be using for this exercise:\n",
    "1. `ping_events.csv`\n",
    "2. `company_candidates.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "`ping_events` schema:\n",
    "\n",
    "|  column name  |  data type  |\n",
    "|---------------|-------------|\n",
    "|  attempt_id   |  int        |\n",
    "|  event_id     |  int        |\n",
    "|  inserttime   |  datetime   |\n",
    "|  metadata     |  string     |\n",
    "\n",
    "In the `metadata` column, `qno` represents the question number within the test and `question_id` represents the question id stored in our database.\n",
    "\n",
    "Sample rows from `ping_events`:\n",
    "\n",
    "|  attempt_id  |  event_id  |  inserttime  |  metadata                      |\n",
    "|:------------:|:----------:|:------------:|:-------------------------------|\n",
    "|      15      |  2         |  05:40       | {\"question_id\": 101, \"qno\": 1} |\n",
    "|      15      |  2         |  05:45       | {\"question_id\": 103, \"qno\": 3} |\n",
    "|      15      |  3         |  05:46       | {\"question_id\": 204, \"qno\": 2} |\n",
    "|      15      |  3         |  05:50       | {\"question_id\": 101, \"qno\": 1} |\n",
    "|      15      |  1         |  05:55       | {}                             |\n",
    "|      16      |  3         |  06:20       | {\"question_id\": 103, \"qno\": 2} |\n",
    "|      16      |  3         |  06:50       | {\"question_id\": 101, \"qno\": 1} |\n",
    "|      16      |  1         |  07:10       | {}                             |\n",
    "\n",
    "Write executable PySpark SQL to create a table with `event_id`, `inserttime`, and `metadata` as an array of tuples grouped by `attempt_id` in a column named `data`:\n",
    "\n",
    "\\* **Note that the data is in array form under one `attempt_id`**\n",
    "\n",
    "|   attempt_id   |   data                                       |\n",
    "|:--------------:|:---------------------------------------------|\n",
    "|       15       | [                                            |\n",
    "|                |  (2, 05:40, {\"question_id\": 101, \"qno\": 1}), |\n",
    "|                |  (2, 05:45, {\"question_id\": 103, \"qno\": 3}), |\n",
    "|                |  (3, 05:46, {\"question_id\": 204, \"qno\": 2}), |\n",
    "|                |  (3, 05:50, {\"question_id\": 101, \"qno\": 1}), |\n",
    "|                |  (1, 05:55, {})                              |\n",
    "|                | ]                                            |\n",
    "|       16       | [                                            |\n",
    "|                |  (3, 06:20, {\"question_id\": 103, \"qno\": 2}), |\n",
    "|                |  (3, 06:50, {\"question_id\": 101, \"qno\": 1}), |\n",
    "|                |  (1, 07:10, {})                              |\n",
    "|                | ]                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ping_events = spark.read.csv(\"./ping_events.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+--------------------+\n",
      "|attempt_id|event_id|         inserttime|            metadata|\n",
      "+----------+--------+-------------------+--------------------+\n",
      "|         1|       1|12/31/2013 05:32:33|                  {}|\n",
      "|         1|       2|12/31/2013 05:32:33|                  {}|\n",
      "|         1|       3|12/31/2013 05:32:46|{'qid': '1455', '...|\n",
      "|         1|       6|12/31/2013 05:33:33|                  {}|\n",
      "|         1|       6|12/31/2013 05:34:33|                  {}|\n",
      "|         1|       6|12/31/2013 05:35:33|                  {}|\n",
      "|         1|       6|12/31/2013 05:36:34|                  {}|\n",
      "|         1|       6|12/31/2013 05:37:34|                  {}|\n",
      "|         1|       3|12/31/2013 05:37:53|{'qid': '117086',...|\n",
      "|         1|       2|12/31/2013 05:38:07|                  {}|\n",
      "|         1|       3|12/31/2013 05:38:09|{'qid': '117086',...|\n",
      "|         1|       3|12/31/2013 05:38:15|{'qid': '1455', '...|\n",
      "|         1|       6|12/31/2013 05:38:33|                  {}|\n",
      "|         1|       3|12/31/2013 05:39:28|{'qid': '117086',...|\n",
      "|         1|       6|12/31/2013 05:39:33|                  {}|\n",
      "|         1|       3|12/31/2013 05:40:08|{'qid': '1455', '...|\n",
      "|         1|       6|12/31/2013 05:40:33|                  {}|\n",
      "|         1|       6|12/31/2013 05:41:33|                  {}|\n",
      "|         1|       3|12/31/2013 05:42:00|{'qid': '117086',...|\n",
      "|         1|       3|12/31/2013 05:42:08|{'qid': '1455', '...|\n",
      "+----------+--------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ping_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ping_events.createOrReplaceTempView(\"ping_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collected_data = spark.sql(\"\"\"\n",
    "    select\n",
    "        int(attempt_id) as attempt_id,\n",
    "        collect_list(struct(int(event_id) as event_id, inserttime, metadata)) as data\n",
    "    from ping_events\n",
    "    group by attempt_id\n",
    "    order by int(attempt_id)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|attempt_id|                data|\n",
      "+----------+--------------------+\n",
      "|         1|[[1,12/31/2013 05...|\n",
      "|         2|[[1,12/31/2013 05...|\n",
      "|         3|    [[null,null,{}]]|\n",
      "|         4|    [[null,null,{}]]|\n",
      "|         5|[[1,01/12/2014 04...|\n",
      "|         6|    [[null,null,{}]]|\n",
      "|         7|    [[null,null,{}]]|\n",
      "|         8|[[6,01/18/2014 05...|\n",
      "|         9|[[1,01/21/2014 12...|\n",
      "|        10|    [[null,null,{}]]|\n",
      "|        11|    [[null,null,{}]]|\n",
      "|        12|[[1,02/13/2014 14...|\n",
      "|        13|[[1,02/19/2014 09...|\n",
      "|        14|    [[null,null,{}]]|\n",
      "|        15|[[1,03/05/2014 12...|\n",
      "|        16|[[6,03/05/2014 16...|\n",
      "|        17|[[1,03/07/2014 13...|\n",
      "|        18|[[1,03/13/2014 13...|\n",
      "|        19|[[1,03/26/2014 16...|\n",
      "|        20|[[1,04/04/2014 04...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collected_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- attempt_id: integer (nullable = true)\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- event_id: integer (nullable = true)\n",
      " |    |    |-- inserttime: string (nullable = true)\n",
      " |    |    |-- metadata: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collected_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_data = collected_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempt_id</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[(1, 12/31/2013 05:32:33, {}), (2, 12/31/2013 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[(1, 12/31/2013 05:37:14, {}), (2, 12/31/2013 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[(1, 01/12/2014 04:34:55, {}), (2, 01/12/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[(6, 01/18/2014 05:13:06, {}), (6, 01/18/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[(1, 01/21/2014 12:24:18, {}), (2, 01/21/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[(1, 02/13/2014 14:02:01, {}), (2, 02/13/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[(1, 02/19/2014 09:54:45, {}), (2, 02/19/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[(None, None, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[(1, 03/05/2014 12:37:57, {}), (2, 03/05/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[(6, 03/05/2014 16:24:19, {}), (1, 03/05/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[(1, 03/07/2014 13:25:13, {}), (2, 03/07/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[(1, 03/13/2014 13:08:23, {}), (2, 03/13/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[(1, 03/26/2014 16:58:31, {}), (2, 03/26/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[(1, 04/04/2014 04:15:21, {}), (2, 04/04/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>[(1, 04/18/2014 05:50:32, {}), (2, 04/18/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>[(1, 04/28/2014 16:54:35, {}), (2, 04/28/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>[(1, 06/30/2014 05:02:21, {}), (2, 06/30/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>[(1, 07/06/2014 10:06:14, {}), (2, 07/06/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>[(1, 07/09/2014 17:59:31, {}), (2, 07/09/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>[(1, 07/24/2014 15:33:13, {}), (2, 07/24/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>[(1, 07/31/2014 05:32:19, {}), (2, 07/31/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>[(1, 08/10/2014 15:30:40, {}), (2, 08/10/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>[(1, 08/10/2014 15:31:33, {}), (2, 08/10/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>[(1, 08/20/2014 18:04:09, {}), (2, 08/20/2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>[(1, 05/20/2017 08:14:27, {'nonce': 'skn5abex'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>172</td>\n",
       "      <td>[(1, 05/30/2017 18:50:42, {'nonce': 'm7ahm0yr'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>173</td>\n",
       "      <td>[(1, 05/31/2017 07:32:09, {'nonce': 'xie1nwir'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>174</td>\n",
       "      <td>[(1, 06/14/2017 07:54:28, {'nonce': 'fqsnahkl'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>175</td>\n",
       "      <td>[(1, 06/14/2017 10:22:31, {'nonce': 'dl6pfzbt'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>176</td>\n",
       "      <td>[(20, 06/15/2017 12:32:23, {'method': 'forced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>177</td>\n",
       "      <td>[(1, 06/17/2017 08:52:37, {'nonce': 'mijd5vm7'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>[(1, 06/18/2017 08:19:15, {'nonce': 'c0mwtiip'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>179</td>\n",
       "      <td>[(1, 07/04/2017 02:36:32, {'nonce': '3xv9m9er'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>[(1, 07/13/2017 17:16:48, {'nonce': 't9xw3vu3'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>[(6, 07/13/2017 20:16:49, {'time_left': '296',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>[(1, 07/14/2017 08:44:04, {'nonce': 't76zlkna'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>[(1, 08/06/2017 07:54:19, {'nonce': 'iqz5y35p'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>184</td>\n",
       "      <td>[(1, 09/18/2017 18:01:56, {'nonce': '4oyk8iig'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>[(1, 09/21/2017 18:25:33, {'nonce': '9ec62rpn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>[(1, 09/26/2017 09:13:53, {'nonce': 'm8iwzhys'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>[(1, 10/21/2017 14:34:56, {'nonce': 'bs7k4gyt'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>188</td>\n",
       "      <td>[(1, 11/07/2017 08:07:38, {'nonce': 'hlpzvt0y'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>[(1, 11/17/2017 02:57:59, {'nonce': 'plqqqguh'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>[(1, 11/29/2017 16:56:34, {'nonce': '722r8b5r'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>[(1, 12/11/2017 17:33:38, {'nonce': 'c9bceou0'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>[(1, 12/15/2017 18:15:36, {'nonce': 'zq2hpq81'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>[(1, 12/28/2017 14:50:04, {'nonce': 'jn5f5e80'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>[(1, 01/20/2018 14:48:52, {'nonce': 'pmn338ar'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>[(5, 01/29/2018 16:23:13, {'qid': '316519', 'q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>[(1, 01/30/2018 06:11:04, {'nonce': '5fbifgig'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>[(6, 01/30/2018 15:35:20, {'time_left': '3445'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>[(1, 02/01/2018 14:51:17, {'nonce': 'eahb08pd'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>[(1, 02/03/2018 08:46:24, {'nonce': 'ssmk0yfs'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>[(1, 02/04/2018 11:16:23, {'nonce': '4kv2ipaf'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     attempt_id                                               data\n",
       "0             1  [(1, 12/31/2013 05:32:33, {}), (2, 12/31/2013 ...\n",
       "1             2  [(1, 12/31/2013 05:37:14, {}), (2, 12/31/2013 ...\n",
       "2             3                                 [(None, None, {})]\n",
       "3             4                                 [(None, None, {})]\n",
       "4             5  [(1, 01/12/2014 04:34:55, {}), (2, 01/12/2014 ...\n",
       "5             6                                 [(None, None, {})]\n",
       "6             7                                 [(None, None, {})]\n",
       "7             8  [(6, 01/18/2014 05:13:06, {}), (6, 01/18/2014 ...\n",
       "8             9  [(1, 01/21/2014 12:24:18, {}), (2, 01/21/2014 ...\n",
       "9            10                                 [(None, None, {})]\n",
       "10           11                                 [(None, None, {})]\n",
       "11           12  [(1, 02/13/2014 14:02:01, {}), (2, 02/13/2014 ...\n",
       "12           13  [(1, 02/19/2014 09:54:45, {}), (2, 02/19/2014 ...\n",
       "13           14                                 [(None, None, {})]\n",
       "14           15  [(1, 03/05/2014 12:37:57, {}), (2, 03/05/2014 ...\n",
       "15           16  [(6, 03/05/2014 16:24:19, {}), (1, 03/05/2014 ...\n",
       "16           17  [(1, 03/07/2014 13:25:13, {}), (2, 03/07/2014 ...\n",
       "17           18  [(1, 03/13/2014 13:08:23, {}), (2, 03/13/2014 ...\n",
       "18           19  [(1, 03/26/2014 16:58:31, {}), (2, 03/26/2014 ...\n",
       "19           20  [(1, 04/04/2014 04:15:21, {}), (2, 04/04/2014 ...\n",
       "20           21  [(1, 04/18/2014 05:50:32, {}), (2, 04/18/2014 ...\n",
       "21           22  [(1, 04/28/2014 16:54:35, {}), (2, 04/28/2014 ...\n",
       "22           23  [(1, 06/30/2014 05:02:21, {}), (2, 06/30/2014 ...\n",
       "23           24  [(1, 07/06/2014 10:06:14, {}), (2, 07/06/2014 ...\n",
       "24           25  [(1, 07/09/2014 17:59:31, {}), (2, 07/09/2014 ...\n",
       "25           26  [(1, 07/24/2014 15:33:13, {}), (2, 07/24/2014 ...\n",
       "26           27  [(1, 07/31/2014 05:32:19, {}), (2, 07/31/2014 ...\n",
       "27           28  [(1, 08/10/2014 15:30:40, {}), (2, 08/10/2014 ...\n",
       "28           29  [(1, 08/10/2014 15:31:33, {}), (2, 08/10/2014 ...\n",
       "29           30  [(1, 08/20/2014 18:04:09, {}), (2, 08/20/2014 ...\n",
       "..          ...                                                ...\n",
       "170         171  [(1, 05/20/2017 08:14:27, {'nonce': 'skn5abex'...\n",
       "171         172  [(1, 05/30/2017 18:50:42, {'nonce': 'm7ahm0yr'...\n",
       "172         173  [(1, 05/31/2017 07:32:09, {'nonce': 'xie1nwir'...\n",
       "173         174  [(1, 06/14/2017 07:54:28, {'nonce': 'fqsnahkl'...\n",
       "174         175  [(1, 06/14/2017 10:22:31, {'nonce': 'dl6pfzbt'...\n",
       "175         176  [(20, 06/15/2017 12:32:23, {'method': 'forced'...\n",
       "176         177  [(1, 06/17/2017 08:52:37, {'nonce': 'mijd5vm7'...\n",
       "177         178  [(1, 06/18/2017 08:19:15, {'nonce': 'c0mwtiip'...\n",
       "178         179  [(1, 07/04/2017 02:36:32, {'nonce': '3xv9m9er'...\n",
       "179         180  [(1, 07/13/2017 17:16:48, {'nonce': 't9xw3vu3'...\n",
       "180         181  [(6, 07/13/2017 20:16:49, {'time_left': '296',...\n",
       "181         182  [(1, 07/14/2017 08:44:04, {'nonce': 't76zlkna'...\n",
       "182         183  [(1, 08/06/2017 07:54:19, {'nonce': 'iqz5y35p'...\n",
       "183         184  [(1, 09/18/2017 18:01:56, {'nonce': '4oyk8iig'...\n",
       "184         185  [(1, 09/21/2017 18:25:33, {'nonce': '9ec62rpn'...\n",
       "185         186  [(1, 09/26/2017 09:13:53, {'nonce': 'm8iwzhys'...\n",
       "186         187  [(1, 10/21/2017 14:34:56, {'nonce': 'bs7k4gyt'...\n",
       "187         188  [(1, 11/07/2017 08:07:38, {'nonce': 'hlpzvt0y'...\n",
       "188         189  [(1, 11/17/2017 02:57:59, {'nonce': 'plqqqguh'...\n",
       "189         190  [(1, 11/29/2017 16:56:34, {'nonce': '722r8b5r'...\n",
       "190         191  [(1, 12/11/2017 17:33:38, {'nonce': 'c9bceou0'...\n",
       "191         192  [(1, 12/15/2017 18:15:36, {'nonce': 'zq2hpq81'...\n",
       "192         193  [(1, 12/28/2017 14:50:04, {'nonce': 'jn5f5e80'...\n",
       "193         194  [(1, 01/20/2018 14:48:52, {'nonce': 'pmn338ar'...\n",
       "194         195  [(5, 01/29/2018 16:23:13, {'qid': '316519', 'q...\n",
       "195         196  [(1, 01/30/2018 06:11:04, {'nonce': '5fbifgig'...\n",
       "196         197  [(6, 01/30/2018 15:35:20, {'time_left': '3445'...\n",
       "197         198  [(1, 02/01/2018 14:51:17, {'nonce': 'eahb08pd'...\n",
       "198         199  [(1, 02/03/2018 08:46:24, {'nonce': 'ssmk0yfs'...\n",
       "199         200  [(1, 02/04/2018 11:16:23, {'nonce': '4kv2ipaf'...\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_data.to_csv(\"./collected_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "Using PySpark, process the resulting table above to determine the time spent in seconds on each attempt. Do not use Pandas to perform this transformation.\n",
    "\n",
    "Each `inserttime` event denotes a user-action. The method we use to calculate the `time_spent` transformation is by looking at the difference between the latest ping and the earliest ping `inserttime`s. For attempt 15, the candidate first looked at `qno 1` at 05:40 then ended the test at 05:55. So we know the user spent 15 minutes or 900 seconds on the test.\n",
    "\n",
    "Using this method, the above table should be transformed into:\n",
    "\n",
    "|   attempt_id   |   test_time_spent   |\n",
    "|:--------------:|:--------------------|\n",
    "|     15         | 900                 |\n",
    "|     16         | 3000                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- You may need more imports for this section. We have included a few to help you out!\n",
    "- The `datetime` module will be very helpful here: https://docs.python.org/2/library/datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StringType, IntegerType, BooleanType, FloatType, ArrayType, StructType, StructField, DateType, TimestampType\n",
    "from pyspark.sql.functions import col, first, last, asc, desc, mean, avg, count, explode, udf\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(attempt_id=1, data=[Row(event_id=1, inserttime='12/31/2013 05:32:33', metadata='{}'), Row(event_id=2, inserttime='12/31/2013 05:32:33', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:32:46', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 05:33:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:34:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:35:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:36:34', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:37:34', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:37:53', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=2, inserttime='12/31/2013 05:38:07', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:38:09', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=3, inserttime='12/31/2013 05:38:15', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 05:38:33', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:39:28', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=6, inserttime='12/31/2013 05:39:33', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:40:08', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 05:40:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:41:33', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:42:00', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=3, inserttime='12/31/2013 05:42:08', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 05:42:33', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 05:44:06', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=6, inserttime='12/31/2013 05:44:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:45:34', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:46:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:48:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:49:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:50:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:51:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:52:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:53:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:55:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:56:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:58:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 05:59:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:00:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:01:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:02:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:03:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:04:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:05:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:06:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:07:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:08:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:09:29', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 06:10:08', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 06:10:32', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 06:10:54', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=6, inserttime='12/31/2013 06:11:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:12:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:13:34', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:14:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:15:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:17:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:18:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:19:34', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:20:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:21:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:22:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:23:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:24:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:25:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:26:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:28:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:29:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:30:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:31:30', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 06:32:13', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 06:32:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:33:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:34:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:35:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:36:34', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:37:32', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 06:38:16', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=3, inserttime='12/31/2013 06:38:24', metadata=\"{'qid': '1455', 'qno': '1'}\"), Row(event_id=6, inserttime='12/31/2013 06:38:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:40:32', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:41:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:42:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:43:31', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:44:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:45:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:46:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:47:30', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:47:31', metadata='{}'), Row(event_id=5, inserttime='12/31/2013 06:47:47', metadata=\"{'qid': '1455'}\"), Row(event_id=5, inserttime='12/31/2013 06:48:13', metadata=\"{'qid': '1455'}\"), Row(event_id=6, inserttime='12/31/2013 06:48:30', metadata='{}'), Row(event_id=5, inserttime='12/31/2013 06:49:11', metadata=\"{'qid': '1455'}\"), Row(event_id=5, inserttime='12/31/2013 06:49:27', metadata=\"{'qid': '1455'}\"), Row(event_id=6, inserttime='12/31/2013 06:49:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:50:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:51:28', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:51:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:52:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:53:28', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:55:29', metadata='{}'), Row(event_id=5, inserttime='12/31/2013 06:56:14', metadata=\"{'qid': '1455'}\"), Row(event_id=6, inserttime='12/31/2013 06:56:28', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:57:29', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 06:58:27', metadata='{}'), Row(event_id=5, inserttime='12/31/2013 06:59:00', metadata=\"{'qid': '1455'}\"), Row(event_id=6, inserttime='12/31/2013 06:59:27', metadata='{}'), Row(event_id=3, inserttime='12/31/2013 06:59:59', metadata=\"{'qid': '117086', 'qno': '2'}\"), Row(event_id=6, inserttime='12/31/2013 07:00:33', metadata='{}'), Row(event_id=6, inserttime='12/31/2013 07:01:34', metadata='{}')])]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_data.rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(row):\n",
    "    attempt_id = row['attempt_id']\n",
    "    data = row['data']\n",
    "    \n",
    "    try:\n",
    "        starttime = datetime.strptime(data[0]['inserttime'], '%m/%d/%Y %H:%M:%S')\n",
    "    except:\n",
    "        starttime = datetime(2018,1,1,12,0,0)\n",
    "        \n",
    "    try:\n",
    "        endtime = datetime.strptime(data[-1]['inserttime'], '%m/%d/%Y %H:%M:%S')\n",
    "    except:\n",
    "        endtime = datetime(2018,1,1,12,0,0)\n",
    "    \n",
    "    time_spent = (endtime - starttime).total_seconds()\n",
    "    \n",
    "    return [Row(attempt_id=attempt_id, test_time_spent=time_spent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solve_times_rdd = collected_data.rdd.flatMap(lambda x: process_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solve_times = spark.createDataFrame(solve_times_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|attempt_id|test_time_spent|\n",
      "+----------+---------------+\n",
      "|         1|         5341.0|\n",
      "|         2|         5399.0|\n",
      "|         3|            0.0|\n",
      "|         4|            0.0|\n",
      "|         5|         5401.0|\n",
      "|         6|            0.0|\n",
      "|         7|            0.0|\n",
      "|         8|          -59.0|\n",
      "|         9|           61.0|\n",
      "|        10|            0.0|\n",
      "|        11|            0.0|\n",
      "|        12|         1431.0|\n",
      "|        13|         4989.0|\n",
      "|        14|            0.0|\n",
      "|        15|         1840.0|\n",
      "|        16|         3749.0|\n",
      "|        17|         5399.0|\n",
      "|        18|         5393.0|\n",
      "|        19|         5226.0|\n",
      "|        20|         5392.0|\n",
      "+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solve_times.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st_pandas = solve_times.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st_pandas.to_csv(\"attempt_solve_times.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "\n",
    "We want to create a table with `company_id` as well:\n",
    "\n",
    "|   company_id   |   attempt_id   |   time_spent   |\n",
    "|:--------------:|:--------------:|:---------------|\n",
    "|   1            |     15         | 900            |\n",
    "|   2            |     16         | 3000           |\n",
    "\n",
    "To get the `company_id` associated with each `attempt_id`, you can use `company_candidates.csv`. After you generate the above table, please store it as an interim table called `attempt_times`. \n",
    "\n",
    "`company_candidates` schema:\n",
    "\n",
    "|  column name  |  data type  |\n",
    "|---------------|-------------|\n",
    "|  attempt_id   |  int        |\n",
    "|  company_id   |  int        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "company_candidates = spark.read.csv(\"./company_candidates.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|attempt_id|company_id|\n",
      "+----------+----------+\n",
      "|         1|         1|\n",
      "|         2|         2|\n",
      "|         3|         4|\n",
      "|         4|         4|\n",
      "|         5|         1|\n",
      "|         6|         3|\n",
      "|         7|         2|\n",
      "|         8|         4|\n",
      "|         9|         1|\n",
      "|        10|         3|\n",
      "|        11|         2|\n",
      "|        12|         3|\n",
      "|        13|         4|\n",
      "|        14|         3|\n",
      "|        15|         3|\n",
      "|        16|         1|\n",
      "|        17|         3|\n",
      "|        18|         3|\n",
      "|        19|         1|\n",
      "|        20|         4|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "company_candidates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solve_times.createOrReplaceTempView(\"solve_times\")\n",
    "company_candidates.createOrReplaceTempView(\"company_candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates_test_times = spark.sql(\"\"\"\n",
    "    select\n",
    "        cc.*,\n",
    "        st.test_time_spent\n",
    "    from company_candidates cc\n",
    "    left join solve_times st on cc.attempt_id=st.attempt_id\n",
    "    order by st.attempt_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+\n",
      "|attempt_id|company_id|test_time_spent|\n",
      "+----------+----------+---------------+\n",
      "|         1|         1|         5341.0|\n",
      "|         2|         2|         5399.0|\n",
      "|         3|         4|            0.0|\n",
      "|         4|         4|            0.0|\n",
      "|         5|         1|         5401.0|\n",
      "|         6|         3|            0.0|\n",
      "|         7|         2|            0.0|\n",
      "|         8|         4|          -59.0|\n",
      "|         9|         1|           61.0|\n",
      "|        10|         3|            0.0|\n",
      "|        11|         2|            0.0|\n",
      "|        12|         3|         1431.0|\n",
      "|        13|         4|         4989.0|\n",
      "|        14|         3|            0.0|\n",
      "|        15|         3|         1840.0|\n",
      "|        16|         1|         3749.0|\n",
      "|        17|         3|         5399.0|\n",
      "|        18|         3|         5393.0|\n",
      "|        19|         1|         5226.0|\n",
      "|        20|         4|         5392.0|\n",
      "+----------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "candidates_test_times.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:\n",
    "\n",
    "Using PySpark, process the resulting table above to determine the time spent on each question. The dictionaries should follow this format: `{question_id: time_in_seconds}`. Do not use Pandas to perform this transformation.\n",
    "\n",
    "Each `inserttime` event denotes a user-action. The method we use to calculate the `time_spent` transformation is by looking at the difference between consecutive ping `inserttime`s. For attempt 15, the candidate first looked at `qno 1` at 05:40 then `qno 3` at 05:45. So we know the user spent 5 minutes so far on `qno 1`.\n",
    "\n",
    "Using this method, the above table should be transformed into:\n",
    "\n",
    "|   attempt_id   |   time_spent              |\n",
    "|:--------------:|:--------------------------|\n",
    "|     15         | {\"1\": 10, \"2\": 4, \"3\": 1} |\n",
    "|     16         | {\"1\": 20, \"2\": 30}        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
